INTRODUCTION TO GLSL
====================
glsl is a statically typed imperative programming language

variables must be assigned a type when declared
	3 scalar types:
	bool, int, float
operators
	+,-,*,/,<,>,<=,>=,==,!=
	+=,-=,*=,/=,++,--
procedures
	can decompose shaders into subroutines with C-like syntax
	declaration needs return type or "void" if none

QUALIFIERS AND BUILT-INS
========================

precision specifiers
	floats are declared with an optional precision specifier that tells the GPU how many bits to use
		lowp - lowest possible
		mediump - default precision
		highp - highest possible
	can specify precision of all floats with
		precision highp float; @ top

constants
	const

in/out
	functions return a single value but can simulate multiple returns with reference types
	type qualifiers for procedure arguments
		in - passes argument value (default behavior)
		inout - passes argument by reference
		out - argument uninitialized, but writing to the value updates the parameter
		const - constant value

built-ins
	built in functions some include
		radians, degrees
		sin, cos, tan, asin, acos, atan
		exp, log, exp2, log2
		pow, sqrt, inversesqrt
		floor, ceil, fract, mod, step
		abs, sign, min, max, clamp
		mix - interpolation

VECTORS
=======

built in types for vectors
	bvec2, bvec3, bvec4 - boolean vector
	ivec2, ivec3, ivec4 - integer vector
	vec2, vec3, vec4    - float vector

swizzles

for accessing components of vectors
	First component of p  = p.x = p.r = p.s = p[0]
	Second component of p = p.y = p.g = p.t = p[1]
	Third component of p  = p.z = p.b = p.u = p[2]
	Fourth component of p = p.w = p.a = p.v = p[3]

can select ranges/subtypes with same symbols i.e. p.xxy

arithmetic operations are applied component-wise

geometric functions
	length(p) - euclidian length
	distance(a,b) - euclidian distance
	dot(a,b) - dot product
	cross(a,b) - cross product
	normalize(a) - rescale to unit length
	faceforward(n, I, nr) - reorient a normal to point away from a surface
	reflect(I, N) - reflects vector I along axis N
	refract(I, N, eta) - refracts I according to Snell's law

BRANCHING
=========

use sparingly!!

if statements
	if (a < 0.5) {
	} else {
	}

comparisons
	component-wise comparison that returns a bvec
	lessThan(a,b), lessThanEqual(a,b)
	greaterThan(a,b), greaterThanEqual(a,b)
	equal(a,b)

boolean operations
	aggregate operations
	any(b), all(b), not(b)

LOOPS
=====

loops are supported but the number of loops must be statically determined and bounded
	for(int i=0; i < 100; ++i){
	}
	while(i < 10){
	i++;
	}

MATRICES
========

special datatypes for low dimensional (square matrices)
	mat2, mat3, mat4
	matrix constructors are in column major order

	mat2 I = mat2(1.0, 0.0,
	              0.0, 1.0);
	// same thing
	mat2 I = mat2(1.0);

	can also be constructed by giving columns
	vec2 a = vec2(1,0);
	vec2 b = vec2(0,1);
	mat2 I = mat2(a,b);

	can access columns with square brackets so
	vec2 a = I[0]; // a = (1,0)

arithmetic
	component wise addition  m + w
	scalar multiplication 2 * m
	component-wise multiplication - matrixCompMult(m,w)
	matrix multiplication - m * w




INTRODUCTION TO FRAGMENT SHADERS
================================

a fragment is the color of some fraction of a pixel

entry point is procedure called main(), no arguments or return value
	output is RGBA color values in a builtin array gl_FragData[]
	n-th entry in the gl_FragData[n] array represents the color that will be written to the color attachment at position n. when rendering to the drawing buffer, which has only one color attachment can use gl_FragColor (gl_FragData[0])

	gl_FragCoord - special input to every gragment shader a vec4 which returns the coordinate of the fragment in device coordinates
	gl_FragCoord.xy - coordinate of the fragment in units relative to top-left of the buffer, y - row, x - column
	gl_FragCoord.z - depth value [0,1] 0 - closest, 1 - furthest away
	gl_FragCoord.w - reciprocal of the homogeneous part of the fragment's position in clip coordinates

THE DISCARD KEYWORD
===================

skip rendering of a fragment with the discard statement

UNIFORM VARIABLES AND TEXTURES
==============================

uniform variables are broadcast to all executions of a shader
	useful for small, frequently changing info
textures are 2d arrays of vectors, declared using sampler2D data type and can be accessed with built in function texture2D()
	vec4 texture2D(
	  in sampler2D texture, - sampler variable
	  in vec2 coordinate, - which data is read [0,1]
	  in float bias = 0.0 - changes filtering
	);

INTRODUCTION TO VERTEX SHADERS
==============================

vertex shaders control how geometry is rendered, and are executed before fragment shaders
	a vertex is of of the corners of a primitive
	primitives are simplices of dimension <= 3
		points - 1 vertex
		lines - 2 vertices
		triangles - 3 vertices
	primitives are drawn by linearly interpolating between their vertices and vertex shaders control where the vertices are placed
entry point for vertex shaders is a void procedure called main()
output is written to gl_Position, which controls the placement of the vertex in clip coordinates

attributes
	in addition to getting inputs from uniform variables, vertex shaders can accept per-vertex information via attribute variables

	attribute vec2 position;

	void main() {
	  gl_Position = vec4(position, 0, 1);
	}

VARYING VARIABLES
=================

Connecting vertex shaders to fragment shaders
	vertex shaders can be used to send information directly to fragment shaders using the varying type qualifier
		varying variables are declared at the global scope within a shader
			must be float, vec2, vec3, or vec4
			by default they are linearly interpolated across the rendered primitive

CLIP COORDINATES
================

projective geometry
	gl_Position is a 4d vector because objects on the GPU are represented in a homogeneous coordinate system
	basic idea is to replace points in a space with lines passing through the origin in a space which is one dimension higher since they can be parameterized by vectors

	two vectors identify the same line if for a non-zero scalar multiple t
	   [x0,y0,z0,w0]  ~   [x1,y1,z1,w1]
                 if and only if
		[t*x0,t*y0,t*z0,t*w0]  ==  [x1,y1,z1,w1]

	lines through the origin can be identified with points in a normal Euclidian space by intersecting them with a hyperplane that does not pass through the origin
		in webgl this hyperplane is taken to be the solution set to w=l
		so any vector [x,y,z,w], corresponds to the 3D point [x/w,y/w,z/w]

points at infinity
	there are extra points corresponding to lines that do not pass through the hyperplane, i.e. where w = 0 called "the points at infinity"
	act like idealized direction vectors instead of proper points

clip coordinates on the gpu
	screenColumn = 0.5 * screenWidth  * (gl_Position.x / gl_Position.w + 1.0)
	screenRow    = 0.5 * screenHeight * (1.0 - gl_Position.y / gl_Position.w)
	depth = gl_Position.z / gl_Position.w

	simplifies testing whether or not a point is visible

		-w < x < w
		-w < y < w
		 0 < z < w

transformations
	any change in reference frame in plane geometry can be encoded as a 4x4 matrix in homogenous coordinates
		used to control position and orientation of the camera, the shape of the viewable frustrum and the location of objects within the scene

	vec4 transformPoint(mat4 transform, vec4 point) {
	  return transform * point;
	}

	transformPoint(A, transformPoint(B, p)) == transformPoint(A * B, p)

the model-view-projection factorization
	3d graphical applications make use of 4 different coordinate systems
		data coordinates - vertices in the model
		world coordinates - coordinates of objects in the scene
		view coordinates - unprojected coordinates of the camera
		clip coordinates - coordinates used by the gpu to render all primitives

	relationship between the coordinate systems is specified with 3 diff transformations
		model - transforms the object from data coordinates to world coordinates
			controls the location of the object in the world
		view - transforms world coordinate system to a viewing coordinate system
			controls the position and orientation of the camera
		projection - transforms the view coordinate system into device clip coordinates
			controls whether the view is orthographic or perspective and the aspect ratio of the camera

TRANSLATIONS
============

a translation of a vector v moving the point o to the origin is a function
	vec3 translatePoint(vec3 v, vec3 o) {
	  return v - o;
	}
but translations are not linear in affine coordinates, but they are in projective homogeneous coordinates
	so they can be written as a matrix

SCALING
=======

scaling transformations stretch or squish the coordinate axes
scaling a vector v by a factor of s along each axis can be define as follows
	vec3 scaleVector(vec3 v, vec3 s) {
	  return s * v;
	}
also linear in projective geometry